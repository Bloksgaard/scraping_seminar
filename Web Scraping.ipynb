{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<center>Accessing data from the web</center>**\n",
    "***<center>Crawling, scraping, and APIs</center>***\n",
    "\n",
    "<center>Snorre Ralund</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Todays message **\n",
    "* Utilize the datasources around you. (Job data and crime)\n",
    "* Knowing how to create your own custom datasets pulling information from many different sources.\n",
    "* You should know all the tricks, but use them with care. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda**\n",
    "\n",
    "* The basics of webscraping\n",
    "    * Connecting, Crawling, Parsing, Storing, Logging.\n",
    "* Hacks: Backdoors, url construction, and analysis of a webpage.\n",
    "* Reliability of your datacollection.\n",
    "* Screen-scraping - Automated browsing\n",
    "    * Interactions:\n",
    "        * Login in, scrolling, pressing buttons.\n",
    "* APIs \n",
    "    * Authentication\n",
    "    * Building queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ethics / Legal Issues\n",
    "* If a regular user can’t access it, we shouldn’t try to get it (That is considered hacking)https://www.dr.dk/nyheder/penge/gjorde-opmaerksom-paa-cpr-hul-nu-bliver-han-politianmeldt-hacking. \n",
    "* Don't hit it to fast: Essentially a DENIAL OF SERVICE attack (DOS). [Again considered hacking](https://www.dr.dk/nyheder/indland/folketingets-hjemmeside-ramt-af-hacker-angreb). \n",
    "* Add headers stating your name and email with your requests to ensure transparency. \n",
    "* Be careful with copyrighted material.\n",
    "* Fair use (don't take everything)\n",
    "* If monetizing on the data, be careful not to be in direct competition with whom you are taking the data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://github.com/snorreralund/images/raw/master/Sk%C3%A6rmbillede%202017-08-03%2014.46.32.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting up the essentials:\n",
    "Good practices:\n",
    "* Transparency\n",
    "* Ratelimiting\n",
    "* Reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'python-requests/2.18.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transparent scraping\n",
    "import requests\n",
    "session = requests.session()\n",
    "#session.headers['email'] = 'youremail'\n",
    "#session.headers['name'] = 'name'\n",
    "session.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A quick tip is that you can change the user agent to a cellphone to obtain more simple formatting of the html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Control the pace of your calls\n",
    "import time\n",
    "def ratelimit():\n",
    "    \"A function that handles the rate of your calls.\"\n",
    "    time.sleep(1)\n",
    "# Reliable requests\n",
    "def request(url,iterations=10,exceptions=(Exception)):\n",
    "    \"\"\"This module ensures that your script does not crash from connection errors.\n",
    "        iterations : Define number of iterations before giving up. \n",
    "        exceptions: Define which exceptions you accept, default is all. \n",
    "    \"\"\"\n",
    "    for iteration in range(iterations):\n",
    "        try:\n",
    "            # add ratelimit function call here\n",
    "            ratelimit() # !!\n",
    "            response = session.get(url)\n",
    "            return response # if succesful it will end the iterations here\n",
    "        except exceptions as e: #  find exceptions in the request library requests.exceptions\n",
    "            print(e) # print or log the exception message.\n",
    "    return None # your code will purposely crash if you don't create a check function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive browsing\n",
    "from selenium import webdriver\n",
    "path2gecko = '/Users/axelengbergpallesen/Downloads/geckodriver' # define path to your geckodriver\n",
    "browser = webdriver.Firefox(executable_path=path2gecko)\n",
    "browser.get('https://www.facebook.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we are ready to get some data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Collecting data from the web: a quick example\n",
    "\n",
    "So let's get some data.\n",
    "\n",
    "Lets say we wanted to obtain high frequency and geolocated information about the danish jobmarket. Then we might build a scraper for [jobfinder.dk](https://www.jobfinder.dk/), [jobindex.dk](https://www.jobindex.dk/) or [jobnet.dk](https://job.jobnet.dk/CV/FindWork/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.jobfinder.dk/jobs/category/it-konsulent'\n",
    "base = 'https://www.jobfinder.dk/'\n",
    "response = request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#print(response.text) # inspect the response to see if it is what you expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job/senior-bi-konsulent-og-arkitekt-30080\n",
      "/job/vi-soeger-skarpe-konsulenter-40316\n",
      "/job/ambitioese-juniorkonsulenter-33672\n",
      "/job/make-impact-it-consultant-33146\n",
      "/job/sikkerhedskonsulent-til-succesfuld-it-virksomhed-41132\n"
     ]
    }
   ],
   "source": [
    "html = response.text\n",
    "link_nodes = html.split('user-jobs__content-item')[1:]\n",
    "for node in link_nodes[0:5]:\n",
    "    link_node = node.split('h2')[1]\n",
    "    link = link_node.split('href=\"')[1]\n",
    "    print(link.split('\"')[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loop over the links and dump the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# make directory\n",
    "# ! mkdir scraping_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# define path\n",
    "base_path = 'scraping_examples/'\n",
    "filename = base_path+'jobfinder_data'\n",
    "f = open(filename,'w')\n",
    "import json\n",
    "# make loop\n",
    "html = response.text\n",
    "link_nodes = html.split('user-jobs__content-item')[1:]\n",
    "for node in link_nodes[0:5]:\n",
    "    link_node = node.split('h2')[1]\n",
    "    link = link_node.split('href=\"')[1]\n",
    "    new_url = base+link\n",
    "    response = request(new_url)\n",
    "    data = {new_url:response.text}\n",
    "    \n",
    "    f.write(json.dumps(data))\n",
    "    f.write('\\n\\r')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 1\n",
    "Get links to the articles listed on this [link](https://www.dr.dk/search/Result?filter_facet_universe=Nyheder&query=kv17&sort=Newest): https://www.dr.dk/search/Result?filter_facet_universe=Nyheder&query=kv17&sort=Newest\n",
    "\n",
    "Loop over the links and save them to a file.\n",
    "\n",
    "** Paging extra **\n",
    "* Use selenium to click on more results or figure out the paging mechanism looking at the activity in the network monitoring of your browser.\n",
    "\n",
    "** Reliability Extra **\n",
    "* When writing the file: provide information about servertime (import the time module), the link, other information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tricks: Backdoors, pseudo-apis, and url construction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Static or dynamic html pages\n",
    "You browser will either get a set of instructions (in javascript) on how to build a page and how interactions will change it, or it will receive a pre-compiled html document.\n",
    "\n",
    "Lets inspect another jobsite: [jobnet.dk](https://job.jobnet.dk/CV/FindWork/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Another examples\n",
    "url = 'https://job.jobnet.dk/CV/FindWork/' # define the link\n",
    "# get the raw html\n",
    "response = request(url)\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "html # inspect to see if it matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This looks a lot shorter. This points us to the fact that the page is build dynamically. \n",
    "\n",
    "Now we can search for instructions and the data that it uses to construct the front.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# get data through the backdoor\n",
    "# backdoor link\n",
    "url = 'https://job.jobnet.dk/CV/FindWork/Search?offset=20'\n",
    "response = request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructions of urls\n",
    "A nice trick is to understand how urls are constructed to communicate with a server. \n",
    "\n",
    "Lets look at how [jobindex.dk](https://www.jobindex.dk/) does it.\n",
    "\n",
    "This can help you navigate the page, without having to parse information from the html or click any buttons.\n",
    "\n",
    "* / is like folders on your computer.\n",
    "* ? entails parameters \n",
    "* = defines a variable: e.g. pageid=1000 or offset = 100 or showNumber=20\n",
    "* & separates different parameters.\n",
    "* + is html for whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2\n",
    "Find the backdoor to the polling data behind the visualization at b.dk (https://www.b.dk/politiko/barometeret). \n",
    "* Follow the above link and look at the network activity for data related responses: .csv xml json \n",
    "* Download the data and parse it using xml2dict (conda install -c conda-forge xmltodict):\n",
    "\n",
    "`data = xmltodict.parse(text)`\n",
    "\n",
    "\n",
    "**extra**\n",
    "\n",
    "Find links to all historical data (either by analyzing the path or by locating the masterfile in the network activity). And set up a loop collecting them all.\n",
    "\n",
    "** extra 2 ** \n",
    "\n",
    "Download precompiled polling data from github:\n",
    "* *** link to a compilation of danish polling [data](https://github.com/erikgahner/polls) ***\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "#xmltodict.parse(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Navigation and Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  HTML Scraping\n",
    "Web Scraping: Automated downloading of web pages and the extraction of specific information from it. \n",
    "\n",
    "Snowball crawling: Finding links, following links, find links, follow links.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parsing and extracting information\n",
    "Retrieving target information from unstructured text.\n",
    "\n",
    "Parsing is used both while crawling and navigating the domain you are scraping from\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## HTML data\n",
    "- Tree structure.\n",
    "    - Children, siblings, parents - descendants. \n",
    "        - Ids and attributes\n",
    "\n",
    "<img src=\"http://www.openbookproject.net/tutorials/getdown/css/images/lesson4/HTMLDOMTree.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we find our way around this tree?\n",
    "\n",
    "* selectors\n",
    "* splitting and regex\n",
    "* traversing html trees (beautifulsoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's download a module that can parse this tree for us.\n",
    "\n",
    "`conda install -c asmeurer beautiful-soup`\n",
    "\n",
    "or \n",
    "`pip install beautifulsoup4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selectors \n",
    "- quick but has to be hardcoded and therefore more likely to break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# selenium example\n",
    "browser.get('https://www.facebook.com')\n",
    "# find login button.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Splitting and searching with Regex \n",
    "\n",
    "Regex is a general language for searching strings. \n",
    "\n",
    "Extremely useful for all extractign information from all sorts of unstructured text data.\n",
    "\n",
    "... however you have to learn it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Custom parsing using Regex\n",
    "Won't go into the details here, but working with text this will come in very handy. \n",
    "Play around with it [here](http://regexr.com/) or in this notebook.\n",
    "\n",
    "* \\+ = 1 or more times\n",
    "* \\* = 0 or more times\n",
    "* {3} = exactly three times\n",
    "* ? = once or none\n",
    "* \\\\ = escape character, used to find characters that has special meaning with regex: e.g. \\+ \\*\n",
    "* () = within the paranthesis is the pattern I care about.\n",
    "* [] = set of characters\n",
    "* ^ = applied within a set, it becomes the inverse of the set defined.\n",
    "* . = any characters except line break\n",
    "* | = or statement. p|b find characters a or b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'defg1234', '789']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "s = 'abcdefg123456789'\n",
    "re.split('bc|56',s)# splitting by a complex pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Advanced parsing using Beautifulsoup\n",
    "Beautifulsoup is a powerful parser build on regex, transforming the raw html into traversable tree of objects. \n",
    "\n",
    "Here I want to show you how to use it for grabbing data about the KV17 election:\n",
    "https://www.altinget.dk/kandidater/kv17/stemmeseddel.aspx\n",
    "\n",
    "Let us analyze the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.altinget.dk/kandidater/kv17/stemmeseddel.aspx?kommune=13'\n",
    "response = request(url)\n",
    "#for i in range(1,86):\n",
    "#    url = 'www.altinget.dk/kandidater/kv17/stemmeseddel.aspx?kommune=%d'%i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "html = response.text\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "node = soup.find('dl',{'class':'candidates-list-parties'}) # find, findall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# children, siblings, parents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for child in list(node.children):\n",
    "    if child['class'][0] == \"candidates-party-name\":\n",
    "        party = child.text\n",
    "        continue\n",
    "    name = child.a.text\n",
    "    link = child.a['href']\n",
    "#    print(name,link)\n",
    "    row = [party,name,link]\n",
    "    candidates.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02. Christiania-Listen</td>\n",
       "      <td>Andreas Bennetzen</td>\n",
       "      <td>/kandidater/kv17/andreas-bennetzen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02. Christiania-Listen</td>\n",
       "      <td>Britta Lillesøe</td>\n",
       "      <td>/kandidater/kv17/Britta-Lillesoee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02. Christiania-Listen</td>\n",
       "      <td>Klaus Haase</td>\n",
       "      <td>/kandidater/kv17/Klaus-Haase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02. Christiania-Listen</td>\n",
       "      <td>Lis Brandstrup</td>\n",
       "      <td>/kandidater/kv17/Lis-Brandstrup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02. Christiania-Listen</td>\n",
       "      <td>Carl Oskar Strange</td>\n",
       "      <td>/kandidater/kv17/carl-oskar-strange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    party                name  \\\n",
       "0  02. Christiania-Listen   Andreas Bennetzen   \n",
       "1  02. Christiania-Listen     Britta Lillesøe   \n",
       "2  02. Christiania-Listen         Klaus Haase   \n",
       "3  02. Christiania-Listen      Lis Brandstrup   \n",
       "4  02. Christiania-Listen  Carl Oskar Strange   \n",
       "\n",
       "                                  link  \n",
       "0   /kandidater/kv17/andreas-bennetzen  \n",
       "1    /kandidater/kv17/Britta-Lillesoee  \n",
       "2         /kandidater/kv17/Klaus-Haase  \n",
       "3      /kandidater/kv17/Lis-Brandstrup  \n",
       "4  /kandidater/kv17/carl-oskar-strange  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(candidates,columns = ['party','name','link'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Getting information about each candidate\n",
    "\n",
    "url = 'https://www.altinget.dk/kandidater/kv17/3010-frank-jensen'\n",
    "response = request(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_nodes = soup.findAll('h3',{'class':'subsection-title h4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for meta_node in meta_nodes:\n",
    "    if meta_node.text == 'Fakta':\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# search for siblings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dl>\n",
       "<dt>Valgt i</dt><dd>2009, 2013</dd>\n",
       "<dt>Uddannelse</dt><dd>Kandidatuddannelse</dd>\n",
       "<dt>Beskæftigelse</dt><dd>Borgmester</dd>\n",
       "<dt>Alder</dt><dd>56 år</dd>\n",
       "</dl>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = meta_node.find_next('dl')\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valgt i 2009, 2013\n",
      "Uddannelse Kandidatuddannelse\n",
      "Beskæftigelse Borgmester\n",
      "Alder 56 år\n"
     ]
    }
   ],
   "source": [
    "candidate_data = {}\n",
    "for cat in node.findAll('dt'):\n",
    "    category_title = cat.get_text()\n",
    "    category_point = cat.find_next_sibling().get_text()\n",
    "    print(category_title,category_point)\n",
    "    candidate_data[category_title] = category_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = soup.findAll('h3',{'class':'panel-title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for answer in answers:\n",
    "    title = answer.text\n",
    "    candidate_answer = answer.find_next('div',{'class':'answer-candidate tooltip in top'}).previous\n",
    "    candidate_data[title] = candidate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alder': '56 år',\n",
       " 'BESKÆFTIGELSE': 'Delvist enig',\n",
       " 'Beskæftigelse': 'Borgmester',\n",
       " 'BÆREDYGTIGHED': 'Delvist enig',\n",
       " 'DAGINSTITUTIONER': 'Delvist enig',\n",
       " 'ENERGI': 'Helt enig',\n",
       " 'ERHVERV': 'Delvist uenig',\n",
       " 'FLYGTNINGE': 'Delvist uenig',\n",
       " 'FOLKESKOLE': 'Delvist uenig',\n",
       " 'FOLKESUNDHED': 'Hverken/eller',\n",
       " 'FOREBYGGELSE': 'Delvist enig',\n",
       " 'FRIVILLIGHED': 'Delvist uenig',\n",
       " 'IDRÆT': 'Helt enig',\n",
       " 'INTEGRATION': 'Delvist uenig',\n",
       " 'KLIMA': 'Helt enig',\n",
       " 'KOMMUNESKAT': 'Delvist uenig',\n",
       " 'KULTUR': 'Helt uenig',\n",
       " 'MILJØ': 'Helt enig',\n",
       " 'TRANSPORT': 'Helt enig',\n",
       " 'Uddannelse': 'Kandidatuddannelse',\n",
       " 'Valgt i': '2009, 2013',\n",
       " 'ÆLDRE': 'Helt enig',\n",
       " 'ÆLDREPLEJE': 'Delvist uenig',\n",
       " 'ØKONOMI': 'Delvist uenig'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#candidate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Hvem er den vageste politiker?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 3: Find the facebook ids of all candidates in the KV17 election\n",
    "* Loop through the first 5 muncipalities and collect all candidates.\n",
    "\n",
    "* Get the facebook link from each candidate's page.\n",
    "\n",
    "- Parse all social media links in the section (Mere information), without knowing the classes in advance.\n",
    "\n",
    "extra: \n",
    "    Parse all information on the page including answers to the candidate test, and count how many 'delvist' answers each politician has. Who is the vaguest politician in denmark?\n",
    "\n",
    "extra:\n",
    "    search for the candidate and kv17 on dr.dk (https://www.dr.dk/search/Result?filter_facet_universe=Nyheder&query=candidate+kv17)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.altinget.dk/kandidater/kv17/jacob-bundsgaard'\n",
    "\n",
    "response = request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = soup.findAll('h3',{'class':'subsection-title h4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3 class=\"subsection-title h4\">Mere information</h3>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = [node for node in nodes if node.text=='Mere information'][0]\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node = node.find_next('dl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for link_node in node.find_all_next('a'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.instagram.com/jacobbundsgaard/\">Instagram </a>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#link_node.a['href']\n",
    "link_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SoMe = {}\n",
    "for link_node in node.find_all_next('dd'):\n",
    "    link_node = link_node.a\n",
    "    name = link_node.text.strip()\n",
    "    link = link_node['href']\n",
    "    SoMe[name] = link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.facebook.com/100002941361500\n"
     ]
    }
   ],
   "source": [
    "if 'Facebook' in SoMe:\n",
    "    print(SoMe['Facebook'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Storing data\n",
    "Storing processed data, logging activity.\n",
    "* in csv, \n",
    "* storing in json,\n",
    "* as picklefile,\n",
    "* as dataframe\n",
    "Install a csv reader and writer:\n",
    "\n",
    "`conda install -c anaconda unicodecsv `\n",
    "\n",
    "or \n",
    "\n",
    "`pip install unicodecsv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now let's try parsing more structured data: Tables.\n",
    "If you are not sure always ask google: \"how to parse html table\"\n",
    "### [Hit the following link](https://www.basketball-reference.com/leagues/NBA_2017.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get('https://www.basketball-reference.com/leagues/NBA_2017.html') # get the html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # import parser\n",
    "\n",
    "bsobj = BeautifulSoup(response.text) # parse the response using beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tables = bsobj.findAll('table') # using the tag to locate tables\n",
    "table = bsobj.select('#confs_standings_E > thead > tr > th.poptip.sort_default_asc.left') # using a specific css selector to locate specific table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### lets look at the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Celtics* (1) \n",
      "53\n",
      "29\n",
      ".646\n",
      "—\n",
      "108.0\n",
      "105.4\n",
      "2.25\n",
      "Cleveland Cavaliers* (2) \n",
      "51\n",
      "31\n",
      ".622\n",
      "2.0\n",
      "110.3\n",
      "107.2\n",
      "2.87\n",
      "Toronto Raptors* (3) \n",
      "51\n",
      "31\n",
      ".622\n",
      "2.0\n",
      "106.9\n",
      "102.6\n",
      "3.65\n",
      "Washington Wizards* (4) \n",
      "49\n",
      "33\n",
      ".598\n",
      "4.0\n",
      "109.2\n",
      "107.4\n",
      "1.36\n",
      "Atlanta Hawks* (5) \n",
      "43\n",
      "39\n",
      ".524\n",
      "10.0\n",
      "103.2\n",
      "104.0\n",
      "-1.23\n",
      "Milwaukee Bucks* (6) \n",
      "42\n",
      "40\n",
      ".512\n",
      "11.0\n",
      "103.6\n",
      "103.8\n",
      "-0.45\n",
      "Indiana Pacers* (7) \n",
      "42\n",
      "40\n",
      ".512\n",
      "11.0\n",
      "105.1\n",
      "105.3\n",
      "-0.64\n",
      "Chicago Bulls* (8) \n",
      "41\n",
      "41\n",
      ".500\n",
      "12.0\n",
      "102.9\n",
      "102.4\n",
      "0.03\n",
      "Miami Heat (9) \n",
      "41\n",
      "41\n",
      ".500\n",
      "12.0\n",
      "103.2\n",
      "102.1\n",
      "0.77\n",
      "Detroit Pistons (10) \n",
      "37\n",
      "45\n",
      ".451\n",
      "16.0\n",
      "101.3\n",
      "102.5\n",
      "-1.29\n",
      "Charlotte Hornets (11) \n",
      "36\n",
      "46\n",
      ".439\n",
      "17.0\n",
      "104.9\n",
      "104.7\n",
      "-0.07\n",
      "New York Knicks (12) \n",
      "31\n",
      "51\n",
      ".378\n",
      "22.0\n",
      "104.3\n",
      "108.0\n",
      "-3.87\n",
      "Orlando Magic (13) \n",
      "29\n",
      "53\n",
      ".354\n",
      "24.0\n",
      "101.1\n",
      "107.6\n",
      "-6.61\n",
      "Philadelphia 76ers (14) \n",
      "28\n",
      "54\n",
      ".341\n",
      "25.0\n",
      "102.4\n",
      "108.1\n",
      "-5.83\n",
      "Brooklyn Nets (15) \n",
      "20\n",
      "62\n",
      ".244\n",
      "33.0\n",
      "105.8\n",
      "112.5\n",
      "-6.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[u'Boston Celtics*\\xa0(1)\\xa0',\n",
       "  u'53',\n",
       "  u'29',\n",
       "  u'.646',\n",
       "  u'\\u2014',\n",
       "  u'108.0',\n",
       "  u'105.4',\n",
       "  u'2.25'],\n",
       " [u'Cleveland Cavaliers*\\xa0(2)\\xa0',\n",
       "  u'51',\n",
       "  u'31',\n",
       "  u'.622',\n",
       "  u'2.0',\n",
       "  u'110.3',\n",
       "  u'107.2',\n",
       "  u'2.87'],\n",
       " [u'Toronto Raptors*\\xa0(3)\\xa0',\n",
       "  u'51',\n",
       "  u'31',\n",
       "  u'.622',\n",
       "  u'2.0',\n",
       "  u'106.9',\n",
       "  u'102.6',\n",
       "  u'3.65'],\n",
       " [u'Washington Wizards*\\xa0(4)\\xa0',\n",
       "  u'49',\n",
       "  u'33',\n",
       "  u'.598',\n",
       "  u'4.0',\n",
       "  u'109.2',\n",
       "  u'107.4',\n",
       "  u'1.36'],\n",
       " [u'Atlanta Hawks*\\xa0(5)\\xa0',\n",
       "  u'43',\n",
       "  u'39',\n",
       "  u'.524',\n",
       "  u'10.0',\n",
       "  u'103.2',\n",
       "  u'104.0',\n",
       "  u'-1.23'],\n",
       " [u'Milwaukee Bucks*\\xa0(6)\\xa0',\n",
       "  u'42',\n",
       "  u'40',\n",
       "  u'.512',\n",
       "  u'11.0',\n",
       "  u'103.6',\n",
       "  u'103.8',\n",
       "  u'-0.45'],\n",
       " [u'Indiana Pacers*\\xa0(7)\\xa0',\n",
       "  u'42',\n",
       "  u'40',\n",
       "  u'.512',\n",
       "  u'11.0',\n",
       "  u'105.1',\n",
       "  u'105.3',\n",
       "  u'-0.64'],\n",
       " [u'Chicago Bulls*\\xa0(8)\\xa0',\n",
       "  u'41',\n",
       "  u'41',\n",
       "  u'.500',\n",
       "  u'12.0',\n",
       "  u'102.9',\n",
       "  u'102.4',\n",
       "  u'0.03'],\n",
       " [u'Miami Heat\\xa0(9)\\xa0',\n",
       "  u'41',\n",
       "  u'41',\n",
       "  u'.500',\n",
       "  u'12.0',\n",
       "  u'103.2',\n",
       "  u'102.1',\n",
       "  u'0.77'],\n",
       " [u'Detroit Pistons\\xa0(10)\\xa0',\n",
       "  u'37',\n",
       "  u'45',\n",
       "  u'.451',\n",
       "  u'16.0',\n",
       "  u'101.3',\n",
       "  u'102.5',\n",
       "  u'-1.29'],\n",
       " [u'Charlotte Hornets\\xa0(11)\\xa0',\n",
       "  u'36',\n",
       "  u'46',\n",
       "  u'.439',\n",
       "  u'17.0',\n",
       "  u'104.9',\n",
       "  u'104.7',\n",
       "  u'-0.07'],\n",
       " [u'New York Knicks\\xa0(12)\\xa0',\n",
       "  u'31',\n",
       "  u'51',\n",
       "  u'.378',\n",
       "  u'22.0',\n",
       "  u'104.3',\n",
       "  u'108.0',\n",
       "  u'-3.87'],\n",
       " [u'Orlando Magic\\xa0(13)\\xa0',\n",
       "  u'29',\n",
       "  u'53',\n",
       "  u'.354',\n",
       "  u'24.0',\n",
       "  u'101.1',\n",
       "  u'107.6',\n",
       "  u'-6.61'],\n",
       " [u'Philadelphia 76ers\\xa0(14)\\xa0',\n",
       "  u'28',\n",
       "  u'54',\n",
       "  u'.341',\n",
       "  u'25.0',\n",
       "  u'102.4',\n",
       "  u'108.1',\n",
       "  u'-5.83'],\n",
       " [u'Brooklyn Nets\\xa0(15)\\xa0',\n",
       "  u'20',\n",
       "  u'62',\n",
       "  u'.244',\n",
       "  u'33.0',\n",
       "  u'105.8',\n",
       "  u'112.5',\n",
       "  u'-6.74']]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for table in tables[0:1]: # iterating through the tables\n",
    "    header = table.findAll('thead')[0] # thead is standard notation for table header\n",
    "    data = table.findAll('tbody')[0] # tbody is standard notation for the data\n",
    "    \n",
    "    head = []\n",
    "    for row in header.findAll('th'): # collect data from header.\n",
    "        #print(row['aria-label'])#.attrs)#,row.text)\n",
    "        head.append(row['aria-label'])\n",
    " #   print(head)\n",
    "    tbody = [] # container for the data\n",
    "    for row in data.findAll('tr'): # tr is standard notation for table rows.\n",
    "#        print row\n",
    "        tempoary_row = []\n",
    "        for cell in row.children: # think of children as indentation in python.\n",
    "            print(cell.get_text())\n",
    "            tempoary_row.append(cell.get_text())\n",
    "        tbody.append(tempoary_row)\n",
    "#        break\n",
    "tbody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for table in tables[0:1]: # pick only the first table\n",
    "    header = table.findAll('thead')[0]\n",
    "    data = table.findAll('tbody')[0]\n",
    "    head = [] # define container for the header\n",
    "    for column in header.findAll('th'): # collect data from header.\n",
    "        head.append(column['aria-label']) # append to header container\n",
    "    rows = [] # define container for the rows\n",
    "    for row in data.findAll('tr'):\n",
    "        temp_row = [] # define tempoary row container\n",
    "        for cell in row.children: # think of children as indentation in python.\n",
    "            val = cell.get_text()\n",
    "            try:    \n",
    "                val = float(val)\n",
    "            except:\n",
    "                pass\n",
    "            temp_row.append(val) # append to tempoary row\n",
    "        rows.append(temp_row) # append tempoary row to row container\n",
    "      \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=head,data=rows) # define the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eastern Conference</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win-Loss Percentage</th>\n",
       "      <th>Games Behind</th>\n",
       "      <th>Points Per Game</th>\n",
       "      <th>Opponent Points Per Game</th>\n",
       "      <th>Simple Rating System</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boston Celtics* (1)</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.646</td>\n",
       "      <td>—</td>\n",
       "      <td>108.0</td>\n",
       "      <td>105.4</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleveland Cavaliers* (2)</td>\n",
       "      <td>51.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>2</td>\n",
       "      <td>110.3</td>\n",
       "      <td>107.2</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toronto Raptors* (3)</td>\n",
       "      <td>51.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>2</td>\n",
       "      <td>106.9</td>\n",
       "      <td>102.6</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington Wizards* (4)</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>4</td>\n",
       "      <td>109.2</td>\n",
       "      <td>107.4</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atlanta Hawks* (5)</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>10</td>\n",
       "      <td>103.2</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Milwaukee Bucks* (6)</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>11</td>\n",
       "      <td>103.6</td>\n",
       "      <td>103.8</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Indiana Pacers* (7)</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>11</td>\n",
       "      <td>105.1</td>\n",
       "      <td>105.3</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chicago Bulls* (8)</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>12</td>\n",
       "      <td>102.9</td>\n",
       "      <td>102.4</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami Heat (9)</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>12</td>\n",
       "      <td>103.2</td>\n",
       "      <td>102.1</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Detroit Pistons (10)</td>\n",
       "      <td>37.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>16</td>\n",
       "      <td>101.3</td>\n",
       "      <td>102.5</td>\n",
       "      <td>-1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Charlotte Hornets (11)</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>17</td>\n",
       "      <td>104.9</td>\n",
       "      <td>104.7</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>New York Knicks (12)</td>\n",
       "      <td>31.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>22</td>\n",
       "      <td>104.3</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Orlando Magic (13)</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>24</td>\n",
       "      <td>101.1</td>\n",
       "      <td>107.6</td>\n",
       "      <td>-6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Philadelphia 76ers (14)</td>\n",
       "      <td>28.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>25</td>\n",
       "      <td>102.4</td>\n",
       "      <td>108.1</td>\n",
       "      <td>-5.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brooklyn Nets (15)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>33</td>\n",
       "      <td>105.8</td>\n",
       "      <td>112.5</td>\n",
       "      <td>-6.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Eastern Conference  Wins  Losses  Win-Loss Percentage Games Behind  \\\n",
       "0        Boston Celtics* (1)   53.0    29.0                0.646            —   \n",
       "1   Cleveland Cavaliers* (2)   51.0    31.0                0.622            2   \n",
       "2       Toronto Raptors* (3)   51.0    31.0                0.622            2   \n",
       "3    Washington Wizards* (4)   49.0    33.0                0.598            4   \n",
       "4         Atlanta Hawks* (5)   43.0    39.0                0.524           10   \n",
       "5       Milwaukee Bucks* (6)   42.0    40.0                0.512           11   \n",
       "6        Indiana Pacers* (7)   42.0    40.0                0.512           11   \n",
       "7         Chicago Bulls* (8)   41.0    41.0                0.500           12   \n",
       "8             Miami Heat (9)   41.0    41.0                0.500           12   \n",
       "9       Detroit Pistons (10)   37.0    45.0                0.451           16   \n",
       "10    Charlotte Hornets (11)   36.0    46.0                0.439           17   \n",
       "11      New York Knicks (12)   31.0    51.0                0.378           22   \n",
       "12        Orlando Magic (13)   29.0    53.0                0.354           24   \n",
       "13   Philadelphia 76ers (14)   28.0    54.0                0.341           25   \n",
       "14        Brooklyn Nets (15)   20.0    62.0                0.244           33   \n",
       "\n",
       "    Points Per Game  Opponent Points Per Game  Simple Rating System  \n",
       "0             108.0                     105.4                  2.25  \n",
       "1             110.3                     107.2                  2.87  \n",
       "2             106.9                     102.6                  3.65  \n",
       "3             109.2                     107.4                  1.36  \n",
       "4             103.2                     104.0                 -1.23  \n",
       "5             103.6                     103.8                 -0.45  \n",
       "6             105.1                     105.3                 -0.64  \n",
       "7             102.9                     102.4                  0.03  \n",
       "8             103.2                     102.1                  0.77  \n",
       "9             101.3                     102.5                 -1.29  \n",
       "10            104.9                     104.7                 -0.07  \n",
       "11            104.3                     108.0                 -3.87  \n",
       "12            101.1                     107.6                 -6.61  \n",
       "13            102.4                     108.1                 -5.83  \n",
       "14            105.8                     112.5                 -6.74  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfs = []\n",
    "for table in tables: # pick only the first table\n",
    "    header = table.findAll('thead')[0]\n",
    "    data = table.findAll('tbody')[0]\n",
    "    head = [] # define container for the header\n",
    "    for column in header.findAll('th'): # collect data from header.\n",
    "        head.append(column.text) # append to header container\n",
    "    rows = [] # define container for the rows\n",
    "    for row in data.findAll('tr'):\n",
    "        temp_row = [] # define tempoary row container\n",
    "        for cell in row.children: # think of children as indentation in python.\n",
    "            val = cell.get_text()\n",
    "            try:    \n",
    "                val = float(val)\n",
    "            except:\n",
    "                pass\n",
    "            temp_row.append(val) # append to tempoary row\n",
    "        rows.append(temp_row) # append tempoary row to row container\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame(columns=head,data=rows) # define the dataframe\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dfs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Screen-scraping and automated interactions\n",
    "* Login in\n",
    "* Scrolling\n",
    "* Pressing buttons\n",
    "\n",
    "Sometimes easier than detective work in the javascript, but has RELIABILITY ISSUES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Installing (and updating everytime something stops working) selenium\n",
    "Selenium is an programmatic interface (api) to your browser. \n",
    "\n",
    "You need to have firefox installed and a version of the Marionette ([Download latest!! version here](https://github.com/mozilla/geckodriver/releases))\n",
    "Then install selenium:\n",
    "\n",
    "`pip install selenium`\n",
    "\n",
    "or \n",
    "\n",
    "`conda install -c conda-forge selenium`\n",
    "\n",
    "If used on a server with no connection to a desktop screen: also install PyDisplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "path2gecko = '/Users/axelengbergpallesen/Downloads/geckodriver' # define path to your geckodriver\n",
    "browser = webdriver.Firefox(executable_path=path2gecko)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#url = 'https://www.facebook.com'\n",
    "#browser.get(url) # go to the page\n",
    "#sel = '#email'# find css selector for the name field\n",
    "#element = browser.find_element_by_css_selector(sel)# locate element\n",
    "#name = 'robot_trespassing@ofir.dk'# define name\n",
    "#element.send_keys(name)# send keys\n",
    "\n",
    "# find password field\n",
    "#sel = '#pass'\n",
    "#element = browser.find_element_by_css_selector(sel)\n",
    "# locate element\n",
    "#password = 'thereyougo'\n",
    "# define password\n",
    "#element.send_keys(password)\n",
    "# send keys\n",
    "\n",
    "sel = '#loginbutton'\n",
    "# Find button. \n",
    "element = browser.find_element_by_css_selector(sel)\n",
    "element.click()\n",
    "\n",
    "# locate element\n",
    "# click button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## scrolling\n",
    "some pages load more results when you reach the bottom of the page, here is a simple script that does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # executing a simple javascript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced scraping methods\n",
    "... ethics\n",
    "... hacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* detective work in the javascript.\n",
    "* changing headers to access mobile content that might be more simple.\n",
    "    * use https://www.whatsmybrowser.org from your phone to find the right headers you need.\n",
    "* using proxies, ssh tunneling.\n",
    "* Simulating human-like behaviour to avoid getting caught by anomaly detection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "mobile_agent = 'Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_2 like Mac OS X) AppleWebKit/537.51.2 (KHTML, like Gecko) Version/7.0 Mobile/11D257 Safari/9537.53'\n",
    "session.headers['User-Agent'] = mobile_agent\n",
    "session.proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# APIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* No parsing. Nice\n",
    "* Fast and efficient.\n",
    "* You can't get all that you can see.\n",
    "* They change.\n",
    "* Ratelimits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Through the API domains control what they want to share. \n",
    "## APIs can be for collecting data or it can be for accessing some service: e.g. tracking users of a website by directing traffic to google analytics, or getting geolocation data from the [Google Geoencoding API](http://maps.googleapis.com/maps/api/geocode/json?language=da&address=1600 Pennsylvania Ave NW, Washington, DC 20500, USA). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Collecting data from APIs\n",
    "Choosing an API: twitter, facebook, reddit, wikipedia, denmarks statistics, etc \n",
    "\n",
    "Get to know the commands, rate limits, and errorcodes by experimenting or simply reading the documentation.\n",
    "\n",
    "Today we will look at the Facebook API [https://developers.facebook.com/docs](https://developers.facebook.com/docs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "instead of looking at the documentation we can go right to experimentations by using their graph explorer app [https://developers.facebook.com/tools/explorer/](https://developers.facebook.com/tools/explorer/). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Authentication\n",
    "Basic authentication: Telling who you are, and a unique address so that can track you.\n",
    "\n",
    "Specific permissions: Some queries is only allowed with special permissions.\n",
    "    * Application specific permissions, gathering user permission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.facebook.com/100002941361500\n"
     ]
    }
   ],
   "source": [
    "# get an ID. \n",
    "print(SoMe['Facebook'])\n",
    "page_id = SoMe['Facebook'].split('/')[-1] # use the facebooklink collected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://graph.facebook.com/v2.10/185952168095456?fields=feed.limit(10){message,id,to,from,comments,likes}&access_token=EAACEdEose0cBAHSnMGWyWm6gjS8mHzev0mUUzY8vILzFUiTZBITdUKYSFOAo4CarRUWi15lYwVtHMZBVWLgKMOMTZCZAnkGaGpE3zzOcuITcSrvSO2v4Ohgsg1cuiWfJyHG1J4o28rixi1gAQZB1sn8rYSokZAJ5xyv2sxY4Je5sQ6oFcK2catHG3XZC2SmM8kZD\n"
     ]
    }
   ],
   "source": [
    "# Authentication! set your access_token\n",
    "base_url = 'https://graph.facebook.com/v2.10/%s'%page_id# define baseurl \n",
    "\n",
    "fields = '?fields=feed.limit(10){message,id,to,from,comments,likes}'# define fields\n",
    "token = 'EAACEdEose0cBAHSnMGWyWm6gjS8mHzev0mUUzY8vILzFUiTZBITdUKYSFOAo4CarRUWi15lYwVtHMZBVWLgKMOMTZCZAnkGaGpE3zzOcuITcSrvSO2v4Ohgsg1cuiWfJyHG1J4o28rixi1gAQZB1sn8rYSokZAJ5xyv2sxY4Je5sQ6oFcK2catHG3XZC2SmM8kZD'\n",
    "authentication = '&access_token=%s'%(token)\n",
    "q = base_url+fields+authentication\n",
    "print(q)\n",
    "response = request(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('-',)\n",
      "no more paging\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "d = response.json()\n",
    "next_link = d['feed']['paging']['next']\n",
    "\n",
    "def grab_next(response):\n",
    "    try:\n",
    "        link = response['feed']['paging']['next']\n",
    "        return link\n",
    "    except:\n",
    "        return False\n",
    "responses = []\n",
    "while True:\n",
    "    print('-')\n",
    "    response = request(next_link).json() \n",
    "    responses.append(response)\n",
    "    next_link = grab_next(response)\n",
    "    if not next_link:\n",
    "        print('no more paging')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## parsing json generic\n",
    "\n",
    "## parsing json with the requests module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rate limiting\n",
    "APIs have rate limits, to ensure reliability you should make sure not break these.\n",
    "\n",
    "Rate limits not always explicitly stated, need to test before launching program or create adaptable program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# waiting using the time module\n",
    "\n",
    "# Intelligent rate limiting. \n",
    "import time\n",
    "logsize = 360\n",
    "timestamps = [time.time()]*logsize\n",
    "requestrate = 1 # number of calls pr second. If the ratelimiting error are thrown update it.\n",
    "ratelimiterrors = 0 #  \n",
    "def ratelimit():\n",
    "    global timestamps\n",
    "    global requestrate\n",
    "    global ratelimiterrors\n",
    "    servertime = time.time()\n",
    "    timestamps.append(servertime)\n",
    "    average_request_rate = (servertime-timestamps[0])/logsize\n",
    "    if ratelimiterrors>0: # adopt new rate\n",
    "        time.sleep(1800)\n",
    "        requestrate+=0.01\n",
    "        print 'updating requestrate to %r'%requestrate\n",
    "        rateli miterrors = 0\n",
    "    if average_request_rate < requestrate: # check if requestrate is to high\n",
    "        time.sleep(1)\n",
    "    timestamps.pop(0) # remove first timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want reliable access you need to create an app. This will allow you to obtain access tokens that last for a month.\n",
    "Go to developers.facebook.com and create an app.\n",
    "\n",
    "Converting the access token is done using the following code snippet:\n",
    "\n",
    "```url = 'https://graph.facebook.com/oauth/access_token?client_id=%s&client_secret=%s&grant_type=fb_exchange_token&fb_exchange_token=%s'%(app_id,app_secret,access_token)```\n",
    "\n",
    "Make sure the access token is specific to you app. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Collecting facebook data from the candidates.\n",
    "\n",
    "First extract ids from the facebook links of each candidate\n",
    "* beware of all the variations in the url.\n",
    "* plus that some have names and not ids. If this is the case convert using the query = frank.jensen?fields=id,name\n",
    "* some are pages and other are profiles, you can only get data from the pages.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reliability!\n",
    "When using found data, you are the curator and you are responsible for enscribing trust in the datacompilation.\n",
    "\n",
    "Reliability is ensured by an interative process, of inspection, error detection and error handling.\n",
    "\n",
    "Build your scrape around making this process easy by:\n",
    "* logging information about the collection (e.g. servertime, size of response to plot weird behavior, size of response over time,  number of calls pr day, detection of holes in your data).\n",
    "* Storing raw data (before parsing it) to be able to backtrack problems, without having to wait for the error to come up.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
